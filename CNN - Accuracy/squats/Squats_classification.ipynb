{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVQh_ip1nDW"
      },
      "source": [
        "## Connect to git ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "988inFxdGH_s",
        "outputId": "03dd502a-a72b-4c75-c796-94c23543ad1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FitnessAI'...\n",
            "remote: Enumerating objects: 5325, done.\u001b[K\n",
            "remote: Counting objects: 100% (1730/1730), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1519/1519), done.\u001b[K\n",
            "remote: Total 5325 (delta 223), reused 1670 (delta 208), pack-reused 3595\u001b[K\n",
            "Receiving objects: 100% (5325/5325), 292.02 MiB | 18.23 MiB/s, done.\n",
            "Resolving deltas: 100% (342/342), done.\n",
            "Updating files: 100% (1912/1912), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sharonnae/FitnessAI.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "um8ivdjk1p_p"
      },
      "source": [
        "## Checkout to the relevant branch ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IBVAdP3GhkT",
        "outputId": "8899d138-43b2-4873-a7da-65c198703c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FitnessAI\n",
            "Branch 'CNN---Accuracy' set up to track remote branch 'CNN---Accuracy' from 'origin'.\n",
            "Switched to a new branch 'CNN---Accuracy'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FitnessAI\n",
        "!git checkout CNN---Accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "azIpU5-A1wGx"
      },
      "source": [
        "# Imports #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1y3mf1tRKzJ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J3o50nAPJ4gn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "! rm -rf '/content/FitnessAI/CNN - Accuracy/deadlift/.ipynb_checkpoints'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GUDeIx0LMUFx"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        transforms.Resize((128,128))\n",
        "     ])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(r'C:\\Users\\mosac\\Git Repositories\\FitnessAI\\CNN - Accuracy\\squats', transform=transform)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split the data into Train set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E6Hs5IQdQQ7V"
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test = random_split(dataset, (0.8, 0.2))\n",
        "len(dataset_train), len(dataset_test)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Print a single image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "5pIu6C9jN2UI",
        "outputId": "b770fad2-9f8d-4456-ebea-dd24277a0530"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mosac\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in dataset:\n",
        "  plt.imshow(i[0][0].numpy())\n",
        "  break\n",
        "# Print a single image and label"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Print a batch of images and labels from the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "U-0cj___LUH4",
        "outputId": "2d47d13b-60f2-4954-8dcb-95d2949c5244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mosac\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Labels\n",
        "classes = {\n",
        "    0: 'correct',\n",
        "    1: 'incorrect',\n",
        "}\n",
        "\n",
        "# A function to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# Print labels\n",
        "print(' '.join(f'{classes[labels[j].item()]:5s}' for j in range(batch_size)))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use a GPU if it is available, and the CPU otherwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU3QxUCQNnI-",
        "outputId": "f15ac685-4638-4449-cae7-2200eaccf0fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cHJ6fddoLYB6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(13456, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "\n",
        "net = Net().to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz48RJ8tS020"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ULgLzkgLiZA",
        "outputId": "f03f8cf8-0a52-46e1-d7f1-72f29b5c967b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mosac\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    20] loss: 0.007\n",
            "[1,    40] loss: 0.006\n",
            "[1,    60] loss: 0.006\n",
            "[1,    80] loss: 0.006\n",
            "[1,   100] loss: 0.006\n",
            "[1,   120] loss: 0.003\n",
            "[1,   140] loss: 0.004\n",
            "[1,   160] loss: 0.003\n",
            "[1,   180] loss: 0.001\n",
            "[1,   200] loss: 0.001\n",
            "[1,   220] loss: 0.004\n",
            "[1,   240] loss: 0.003\n",
            "[2,    20] loss: 0.001\n",
            "[2,    40] loss: 0.001\n",
            "[2,    60] loss: 0.002\n",
            "[2,    80] loss: 0.002\n",
            "[2,   100] loss: 0.000\n",
            "[2,   120] loss: 0.001\n",
            "[2,   140] loss: 0.002\n",
            "[2,   160] loss: 0.002\n",
            "[2,   180] loss: 0.001\n",
            "[2,   200] loss: 0.000\n",
            "[2,   220] loss: 0.001\n",
            "[2,   240] loss: 0.000\n",
            "[3,    20] loss: 0.001\n",
            "[3,    40] loss: 0.001\n",
            "[3,    60] loss: 0.000\n",
            "[3,    80] loss: 0.001\n",
            "[3,   100] loss: 0.002\n",
            "[3,   120] loss: 0.001\n",
            "[3,   140] loss: 0.000\n",
            "[3,   160] loss: 0.002\n",
            "[3,   180] loss: 0.003\n",
            "[3,   200] loss: 0.000\n",
            "[3,   220] loss: 0.000\n",
            "[3,   240] loss: 0.000\n",
            "[4,    20] loss: 0.000\n",
            "[4,    40] loss: 0.002\n",
            "[4,    60] loss: 0.000\n",
            "[4,    80] loss: 0.001\n",
            "[4,   100] loss: 0.003\n",
            "[4,   120] loss: 0.001\n",
            "[4,   140] loss: 0.001\n",
            "[4,   160] loss: 0.000\n",
            "[4,   180] loss: 0.000\n",
            "[4,   200] loss: 0.000\n",
            "[4,   220] loss: 0.002\n",
            "[4,   240] loss: 0.000\n",
            "[5,    20] loss: 0.001\n",
            "[5,    40] loss: 0.000\n",
            "[5,    60] loss: 0.000\n",
            "[5,    80] loss: 0.001\n",
            "[5,   100] loss: 0.002\n",
            "[5,   120] loss: 0.000\n",
            "[5,   140] loss: 0.001\n",
            "[5,   160] loss: 0.000\n",
            "[5,   180] loss: 0.000\n",
            "[5,   200] loss: 0.000\n",
            "[5,   220] loss: 0.000\n",
            "[5,   240] loss: 0.003\n",
            "[6,    20] loss: 0.001\n",
            "[6,    40] loss: 0.000\n",
            "[6,    60] loss: 0.001\n",
            "[6,    80] loss: 0.001\n",
            "[6,   100] loss: 0.002\n",
            "[6,   120] loss: 0.000\n",
            "[6,   140] loss: 0.000\n",
            "[6,   160] loss: 0.002\n",
            "[6,   180] loss: 0.000\n",
            "[6,   200] loss: 0.002\n",
            "[6,   220] loss: 0.000\n",
            "[6,   240] loss: 0.000\n",
            "[7,    20] loss: 0.000\n",
            "[7,    40] loss: 0.000\n",
            "[7,    60] loss: 0.001\n",
            "[7,    80] loss: 0.000\n",
            "[7,   100] loss: 0.000\n",
            "[7,   120] loss: 0.001\n",
            "[7,   140] loss: 0.001\n",
            "[7,   160] loss: 0.001\n",
            "[7,   180] loss: 0.000\n",
            "[7,   200] loss: 0.000\n",
            "[7,   220] loss: 0.000\n",
            "[7,   240] loss: 0.000\n",
            "[8,    20] loss: 0.000\n",
            "[8,    40] loss: 0.001\n",
            "[8,    60] loss: 0.001\n",
            "[8,    80] loss: 0.001\n",
            "[8,   100] loss: 0.001\n",
            "[8,   120] loss: 0.000\n",
            "[8,   140] loss: 0.000\n",
            "[8,   160] loss: 0.001\n",
            "[8,   180] loss: 0.001\n",
            "[8,   200] loss: 0.000\n",
            "[8,   220] loss: 0.000\n",
            "[8,   240] loss: 0.000\n",
            "[9,    20] loss: 0.002\n",
            "[9,    40] loss: 0.001\n",
            "[9,    60] loss: 0.000\n",
            "[9,    80] loss: 0.001\n",
            "[9,   100] loss: 0.001\n",
            "[9,   120] loss: 0.000\n",
            "[9,   140] loss: 0.000\n",
            "[9,   160] loss: 0.001\n",
            "[9,   180] loss: 0.001\n",
            "[9,   200] loss: 0.000\n",
            "[9,   220] loss: 0.000\n",
            "[9,   240] loss: 0.000\n",
            "[10,    20] loss: 0.000\n",
            "[10,    40] loss: 0.000\n",
            "[10,    60] loss: 0.000\n",
            "[10,    80] loss: 0.000\n",
            "[10,   100] loss: 0.000\n",
            "[10,   120] loss: 0.000\n",
            "[10,   140] loss: 0.000\n",
            "[10,   160] loss: 0.001\n",
            "[10,   180] loss: 0.000\n",
            "[10,   200] loss: 0.000\n",
            "[10,   220] loss: 0.000\n",
            "[10,   240] loss: 0.000\n",
            "[11,    20] loss: 0.001\n",
            "[11,    40] loss: 0.000\n",
            "[11,    60] loss: 0.001\n",
            "[11,    80] loss: 0.000\n",
            "[11,   100] loss: 0.000\n",
            "[11,   120] loss: 0.000\n",
            "[11,   140] loss: 0.001\n",
            "[11,   160] loss: 0.001\n",
            "[11,   180] loss: 0.000\n",
            "[11,   200] loss: 0.000\n",
            "[11,   220] loss: 0.000\n",
            "[11,   240] loss: 0.000\n",
            "[12,    20] loss: 0.000\n",
            "[12,    40] loss: 0.001\n",
            "[12,    60] loss: 0.001\n",
            "[12,    80] loss: 0.000\n",
            "[12,   100] loss: 0.000\n",
            "[12,   120] loss: 0.001\n",
            "[12,   140] loss: 0.000\n",
            "[12,   160] loss: 0.000\n",
            "[12,   180] loss: 0.000\n",
            "[12,   200] loss: 0.001\n",
            "[12,   220] loss: 0.002\n",
            "[12,   240] loss: 0.000\n",
            "[13,    20] loss: 0.000\n",
            "[13,    40] loss: 0.001\n",
            "[13,    60] loss: 0.000\n",
            "[13,    80] loss: 0.000\n",
            "[13,   100] loss: 0.000\n",
            "[13,   120] loss: 0.000\n",
            "[13,   140] loss: 0.001\n",
            "[13,   160] loss: 0.000\n",
            "[13,   180] loss: 0.000\n",
            "[13,   200] loss: 0.000\n",
            "[13,   220] loss: 0.000\n",
            "[13,   240] loss: 0.001\n",
            "[14,    20] loss: 0.000\n",
            "[14,    40] loss: 0.000\n",
            "[14,    60] loss: 0.000\n",
            "[14,    80] loss: 0.000\n",
            "[14,   100] loss: 0.000\n",
            "[14,   120] loss: 0.001\n",
            "[14,   140] loss: 0.000\n",
            "[14,   160] loss: 0.000\n",
            "[14,   180] loss: 0.000\n",
            "[14,   200] loss: 0.000\n",
            "[14,   220] loss: 0.000\n",
            "[14,   240] loss: 0.000\n",
            "[15,    20] loss: 0.000\n",
            "[15,    40] loss: 0.001\n",
            "[15,    60] loss: 0.000\n",
            "[15,    80] loss: 0.000\n",
            "[15,   100] loss: 0.001\n",
            "[15,   120] loss: 0.000\n",
            "[15,   140] loss: 0.000\n",
            "[15,   160] loss: 0.000\n",
            "[15,   180] loss: 0.000\n",
            "[15,   200] loss: 0.000\n",
            "[15,   220] loss: 0.000\n",
            "[15,   240] loss: 0.000\n",
            "[16,    20] loss: 0.000\n",
            "[16,    40] loss: 0.000\n",
            "[16,    60] loss: 0.000\n",
            "[16,    80] loss: 0.000\n",
            "[16,   100] loss: 0.001\n",
            "[16,   120] loss: 0.000\n",
            "[16,   140] loss: 0.000\n",
            "[16,   160] loss: 0.000\n",
            "[16,   180] loss: 0.000\n",
            "[16,   200] loss: 0.000\n",
            "[16,   220] loss: 0.000\n",
            "[16,   240] loss: 0.001\n",
            "[17,    20] loss: 0.000\n",
            "[17,    40] loss: 0.000\n",
            "[17,    60] loss: 0.000\n",
            "[17,    80] loss: 0.000\n",
            "[17,   100] loss: 0.000\n",
            "[17,   120] loss: 0.000\n",
            "[17,   140] loss: 0.000\n",
            "[17,   160] loss: 0.000\n",
            "[17,   180] loss: 0.001\n",
            "[17,   200] loss: 0.000\n",
            "[17,   220] loss: 0.000\n",
            "[17,   240] loss: 0.000\n",
            "[18,    20] loss: 0.000\n",
            "[18,    40] loss: 0.000\n",
            "[18,    60] loss: 0.000\n",
            "[18,    80] loss: 0.000\n",
            "[18,   100] loss: 0.000\n",
            "[18,   120] loss: 0.000\n",
            "[18,   140] loss: 0.000\n",
            "[18,   160] loss: 0.000\n",
            "[18,   180] loss: 0.000\n",
            "[18,   200] loss: 0.000\n",
            "[18,   220] loss: 0.000\n",
            "[18,   240] loss: 0.000\n",
            "[19,    20] loss: 0.000\n",
            "[19,    40] loss: 0.000\n",
            "[19,    60] loss: 0.000\n",
            "[19,    80] loss: 0.000\n",
            "[19,   100] loss: 0.000\n",
            "[19,   120] loss: 0.000\n",
            "[19,   140] loss: 0.000\n",
            "[19,   160] loss: 0.000\n",
            "[19,   180] loss: 0.000\n",
            "[19,   200] loss: 0.000\n",
            "[19,   220] loss: 0.000\n",
            "[19,   240] loss: 0.000\n",
            "[20,    20] loss: 0.000\n",
            "[20,    40] loss: 0.000\n",
            "[20,    60] loss: 0.000\n",
            "[20,    80] loss: 0.000\n",
            "[20,   100] loss: 0.000\n",
            "[20,   120] loss: 0.000\n",
            "[20,   140] loss: 0.000\n",
            "[20,   160] loss: 0.000\n",
            "[20,   180] loss: 0.000\n",
            "[20,   200] loss: 0.000\n",
            "[20,   220] loss: 0.000\n",
            "[20,   240] loss: 0.000\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "#Runtime - 2:21 Seconds\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        outputs = torch.flatten(outputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 20 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCt0x2N4S2PA"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxvKL33CR_O8",
        "outputId": "dba2e2b1-7544-4c6c-cdb0-8641b3b8ccb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 69 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy {100 - (100 * correct // total)} %')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
